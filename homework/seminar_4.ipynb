{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инструменты для работы с языком"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... или зачем нужна предобработка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача: классификация твитов по тональности\n",
    "\n",
    "У нас есть датасет из твитов, про каждый указано, как он эмоционально окрашен: положительно или отрицательно. Задача: предсказывать эмоциональную окраску.\n",
    "\n",
    "Классификацию по тональности используют в рекомендательных системах, чтобы понять, понравилось ли людям кафе, кино, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6929, 2), (794, 2))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>эти розы для прекрасной мамочки)))=_=]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>И да, у меня в этом году серьезные проблемы со...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>♥Обожаю людей, которые заставляют меня смеятьс...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>Вчера нашла в почтовом ящике пустую упаковку и...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>очень долгожданный и хороший день был)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0  positive            эти розы для прекрасной мамочки)))=_=]]\n",
       "1  negative  И да, у меня в этом году серьезные проблемы со...\n",
       "2  positive  ♥Обожаю людей, которые заставляют меня смеятьс...\n",
       "3  negative  Вчера нашла в почтовом ящике пустую упаковку и...\n",
       "4  positive             очень долгожданный и хороший день был)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train.text.apply(word_tokenize).apply(len).hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = df_train['text'], df_train['label'], df_test['text'], df_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       positive\n",
       "1       negative\n",
       "2       positive\n",
       "3       negative\n",
       "4       positive\n",
       "          ...   \n",
       "6924    positive\n",
       "6925    positive\n",
       "6926    positive\n",
       "6927    positive\n",
       "6928    positive\n",
       "Name: label, Length: 6929, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: классификация необработанных n-грамм\n",
    "\n",
    "### Векторизаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # можно заменить на любимый классификатор\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что такое n-граммы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если',), ('б',), ('мне',), ('платили',), ('каждый',), ('раз',)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'Если б мне платили каждый раз'.split()\n",
    "list(ngrams(sent, 1)) # униграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б'),\n",
       " ('б', 'мне'),\n",
       " ('мне', 'платили'),\n",
       " ('платили', 'каждый'),\n",
       " ('каждый', 'раз')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 2)) # биграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б', 'мне'),\n",
       " ('б', 'мне', 'платили'),\n",
       " ('мне', 'платили', 'каждый'),\n",
       " ('платили', 'каждый', 'раз')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 3)) # триграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б', 'мне', 'платили', 'каждый'),\n",
       " ('б', 'мне', 'платили', 'каждый', 'раз')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 5)) # ... пентаграммы?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведем к нижнему регистру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.str.lower()\n",
    "x_test = x_test.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6929,), (794,))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 эти розы для прекрасной мамочки)))=_=]]\n",
       "1       и да, у меня в этом году серьезные проблемы со...\n",
       "2       ♥обожаю людей, которые заставляют меня смеятьс...\n",
       "3       вчера нашла в почтовом ящике пустую упаковку и...\n",
       "4                  очень долгожданный и хороший день был)\n",
       "                              ...                        \n",
       "6924    ссора. я: я не твоя жена, чтобы ты мог мне зап...\n",
       "6925                                  к\\nр\\nа\\nс\\nу\\nн\\nя\n",
       "6926    опять улетаю сегодня в ночь, до 30 не будет в ...\n",
       "6927    хватит гарусных статусов!!!!!лето!!!)))пора на...\n",
       "6928                    ахахахахахах! !!! лёва помнишь???\n",
       "Name: text, Length: 6929, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой способ извлечь фичи из текстовых данных -- векторизаторы: CountVectorizer и TfidfVectorizer\n",
    "\n",
    "Объект CountVectorizer делает очень простую вещь:\n",
    "* строит для каждого документа (каждой пришедшей ему строки) вектор размерности n, где n -- количество слов или n-грам во всём корпусе\n",
    "* заполняет каждый i-тый элемент количеством вхождений слова в данный документ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train) # bow -- bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ngram_range отвечает за то, какие n-граммы мы используем в качестве фичей:<br/>\n",
    "ngram_range=(1, 1) -- униграммы<br/>\n",
    "ngram_range=(3, 3) -- триграммы<br/>\n",
    "ngram_range=(1, 3) -- униграммы, биграммы и триграммы.\n",
    "\n",
    "В vec.vocabulary_ лежит словарь: мэппинг слов к их индексам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('эти', 78958),\n",
       " ('розы', 58767),\n",
       " ('для', 15893),\n",
       " ('прекрасной', 53692),\n",
       " ('мамочки', 31886),\n",
       " ('эти розы', 78992),\n",
       " ('розы для', 58768),\n",
       " ('для прекрасной', 15975),\n",
       " ('прекрасной мамочки', 53695),\n",
       " ('да', 13988)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vec.vocabulary_.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6929x22497 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 70895 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.81      0.64       171\n",
      "    positive       0.94      0.81      0.87       623\n",
      "\n",
      "    accuracy                           0.81       794\n",
      "   macro avg       0.74      0.81      0.76       794\n",
      "weighted avg       0.85      0.81      0.82       794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сделать то же самое для триграмм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.76      0.59       163\n",
      "    positive       0.93      0.79      0.85       631\n",
      "\n",
      "    accuracy                           0.78       794\n",
      "   macro avg       0.70      0.77      0.72       794\n",
      "weighted avg       0.84      0.78      0.80       794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 3))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfidfVectorizer делает то же, что и CountVectorizer, но в качестве значений – tf-idf каждого слова.\n",
    "\n",
    "Как считается tf-idf:\n",
    "\n",
    "tf (term frequency) – относительная частотность слова в документе:\n",
    "$$ tf(t,d) = \\frac{n_{t}}{\\sum_k n_{k}} $$\n",
    "\n",
    "idf (inverse document frequency) – обратная частота документов, в которых есть это слово:\n",
    "$$ idf(t, D) = \\mbox{log} \\frac{|D|}{|{d : t \\in d}|} $$\n",
    "\n",
    "Потом просто их перемножаем:\n",
    "$$tfidf_(t,d,D) = tf(t,d) \\times idf(i, D)$$\n",
    "\n",
    "Сакральный смысл – если слово часто встречается в одном документе, но в целом по корпусу встречается в небольшом \n",
    "количестве документов, у него высокий TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.79      0.60       155\n",
      "    positive       0.94      0.79      0.86       639\n",
      "\n",
      "    accuracy                           0.79       794\n",
      "   macro avg       0.71      0.79      0.73       794\n",
      "weighted avg       0.85      0.79      0.81       794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этот раз получилось хуже :( Вернёмся к CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['эти', 'розы', 'для', 'прекрасной', 'мамочки)))=_=]]']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация\n",
    "\n",
    "По дефолту векторизаторы используют свои *токенизаторы*, но можно это изменить, задав аргумент `tokenizer`.\n",
    "\n",
    "Самый наивный способ токенизировать текст -- разделить с помощью `split`. Но `split` упускает очень много всего, например, банально не отделяет пунктуацию от слов. Кроме этого, есть ещё много менее тривиальных проблем. Поэтому лучше использовать готовые токенизаторы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Но', 'не', 'каждый', 'хочет', 'что-то', 'исправлять', ':', '(']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = 'Но не каждый хочет что-то исправлять:('\n",
    "word_tokenize(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В nltk вообще есть довольно много токенизаторов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BlanklineTokenizer',\n",
       " 'LegalitySyllableTokenizer',\n",
       " 'LineTokenizer',\n",
       " 'MWETokenizer',\n",
       " 'NLTKWordTokenizer',\n",
       " 'PunktSentenceTokenizer',\n",
       " 'RegexpTokenizer',\n",
       " 'ReppTokenizer',\n",
       " 'SExprTokenizer',\n",
       " 'SpaceTokenizer',\n",
       " 'StanfordSegmenter',\n",
       " 'SyllableTokenizer',\n",
       " 'TabTokenizer',\n",
       " 'TextTilingTokenizer',\n",
       " 'ToktokTokenizer',\n",
       " 'TreebankWordDetokenizer',\n",
       " 'TreebankWordTokenizer',\n",
       " 'TweetTokenizer',\n",
       " 'WhitespaceTokenizer',\n",
       " 'WordPunctTokenizer',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_treebank_word_tokenizer',\n",
       " 'api',\n",
       " 'blankline_tokenize',\n",
       " 'casual',\n",
       " 'casual_tokenize',\n",
       " 'destructive',\n",
       " 'legality_principle',\n",
       " 'line_tokenize',\n",
       " 'load',\n",
       " 'mwe',\n",
       " 'punkt',\n",
       " 're',\n",
       " 'regexp',\n",
       " 'regexp_span_tokenize',\n",
       " 'regexp_tokenize',\n",
       " 'repp',\n",
       " 'sent_tokenize',\n",
       " 'sexpr',\n",
       " 'sexpr_tokenize',\n",
       " 'simple',\n",
       " 'sonority_sequencing',\n",
       " 'stanford_segmenter',\n",
       " 'string_span_tokenize',\n",
       " 'texttiling',\n",
       " 'toktok',\n",
       " 'treebank',\n",
       " 'util',\n",
       " 'word_tokenize',\n",
       " 'wordpunct_tokenize']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "dir(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Они умеют выдавать индексы начала и конца каждого токена:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2), (3, 5), (6, 12), (13, 18), (19, 25), (26, 38)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wh_tok = tokenize.WhitespaceTokenizer()\n",
    "list(wh_tok.span_tokenize(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(если вам было интересно, зачем вообще включать в модуль токенизатор, который работает как `.split()` :))\n",
    "\n",
    "Некторые токенизаторы ведут себя специфично:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"don't\", 'stop', 'me', ':)']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize.TweetTokenizer().tokenize(\"don't stop me:)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для некоторых задач это может быть полезно.\n",
    "\n",
    "А некоторые -- вообще не для текста на естественном языке (не очень понятно, зачем это в nltk :)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(a (b c))', 'd', 'e', '(f)']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize.SExprTokenizer().tokenize(\"(a (b c)) d e (f)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стоп-слова и пунктуация\n",
    "\n",
    "*Стоп-слова* -- это слова, которые часто встречаются практически в любом тексте и ничего интересного не говорят о конретном документе, то есть играют роль шума. Поэтому их принято убирать. По той же причине убирают и пунктуацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    }
   ],
   "source": [
    "# у вас здесь, вероятно, выскочит ошибка и надо будет загрузить стоп слова (в тексте ошибки написано, как)\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = stopwords.words('russian') + list(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В векторизаторах за стоп-слова, логичным образом, отвечает аргумент `stop_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.52      0.83      0.63       161\n",
      "    positive       0.95      0.80      0.87       633\n",
      "\n",
      "    accuracy                           0.81       794\n",
      "   macro avg       0.73      0.81      0.75       794\n",
      "weighted avg       0.86      0.81      0.82       794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=noise)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось чууть лучше. Что ещё можно сделать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лемматизация\n",
    "\n",
    "Лемматизация – это сведение разных форм одного слова к начальной форме – *лемме*. Почему это хорошо?\n",
    "* Во-первых, мы хотим рассматривать как отдельную фичу каждое *слово*, а не каждую его отдельную форму.\n",
    "* Во-вторых, некоторые стоп-слова стоят только в начальной форме, и без лематизации выкидываем мы только её.\n",
    "\n",
    "Для русского есть два хороших лемматизатора: mystem и pymorphy:\n",
    "\n",
    "### [Mystem](https://tech.yandex.ru/mystem/)\n",
    "Как с ним работать:\n",
    "* можно скачать mystem и запускать [из терминала с разными параметрами](https://tech.yandex.ru/mystem/doc/)\n",
    "* [pymystem3](https://pythonhosted.org/pymystem3/pymystem3.html) - обертка для питона, работает медленнее, но это удобно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "mystem_analyzer = Mystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы инициализировали Mystem c дефолтными параметрами. А вообще параметры есть такие:\n",
    "* mystem_bin - путь к `mystem`, если их несколько\n",
    "* grammar_info - нужна ли грамматическая информация или только леммы (по дефолту нужна)\n",
    "* disambiguation - нужно ли снятие омонимии - дизамбигуация (по дефолту нужна)\n",
    "* entire_input - нужно ли сохранять в выводе все (пробелы всякие, например), или можно выкинуть (по дефолту оставляется все)\n",
    "\n",
    "Методы Mystem принимают строку, токенизатор вшит внутри. Можно, конечно, и пословно анализировать, но тогда он не сможет учитывать контекст.\n",
    "\n",
    "Можно просто лемматизировать текст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['но', ' ', 'не', ' ', 'каждый', ' ', 'хотеть', ' ', 'что-то', ' ', 'исправлять', ':(\\n']\n"
     ]
    }
   ],
   "source": [
    "print(mystem_analyzer.lemmatize(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А можно получить грамматическую информацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'lex': 'но', 'wt': 0.9998906299, 'gr': 'CONJ='}],\n",
       "  'text': 'Но'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'не', 'wt': 1, 'gr': 'PART='}], 'text': 'не'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'каждый',\n",
       "    'wt': 0.9985975799,\n",
       "    'gr': 'APRO=(вин,ед,муж,неод|им,ед,муж)'}],\n",
       "  'text': 'каждый'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'хотеть',\n",
       "    'wt': 1,\n",
       "    'gr': 'V,несов,пе=непрош,ед,изъяв,3-л'}],\n",
       "  'text': 'хочет'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'что-то', 'wt': 1, 'gr': 'SPRO,ед,сред,неод=(вин|им)'}],\n",
       "  'text': 'что-то'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'исправлять', 'wt': 1, 'gr': 'V,пе=инф,несов'}],\n",
       "  'text': 'исправлять'},\n",
       " {'text': ':(\\n'}]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_analyzer.analyze(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте терепь лемматизатор майстема в качестве токенизатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def my_preproc(text):\n",
    "    text = re.sub('[{}]'.format(punctuation), '', text)\n",
    "    text = mystem_analyzer.lemmatize(text)\n",
    "    return [word for word in text if word not in stopwords.words('russian') + [' ', '\\n']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.85      0.69       174\n",
      "    positive       0.95      0.82      0.88       620\n",
      "\n",
      "    accuracy                           0.83       794\n",
      "   macro avg       0.76      0.84      0.78       794\n",
      "weighted avg       0.87      0.83      0.84       794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=my_preproc)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Pymorphy](http://pymorphy2.readthedocs.io/en/latest/)\n",
    "Это модуль на питоне, довольно быстрый и с кучей функций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "pymorphy2_analyzer = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pymorphy2 работает с отдельными словами. Если дать ему на вход предложение - он его просто не лемматизирует, т.к. не понимает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='платили', tag=OpencorporaTag('VERB,impf,tran plur,past,indc'), normal_form='платить', score=1.0, methods_stack=((<DictionaryAnalyzer>, 'платили', 2368, 10),))]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana = pymorphy2_analyzer.parse(sent[3])\n",
    "ana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'платить'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana[0].normal_form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь напишите аналогичную функцию для лемматизации с pymorphy2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что будет, если использовать её в качестве препроцессора? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mystem vs. pymorphy\n",
    "\n",
    "1) *Мы надеемся, что вы пользуетесь линуксом*, но mystem работает невероятно медленно под windows на больших текстах.\n",
    "\n",
    "2) *Снятие омонимии*. Mystem умеет снимать омонимию по контексту (хотя не всегда преуспевает), pymorphy2 берет на вход одно слово и соответственно вообще не умеет дизамбигуировать по контексту:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'сорока', 'analysis': [{'gr': 'NUM=(пр|дат|род|твор)', 'lex': 'сорок'}]}\n",
      "{'text': 'Сорока', 'analysis': [{'gr': 'S,жен,од=им,ед', 'lex': 'сорока'}]}\n"
     ]
    }
   ],
   "source": [
    "homonym1 = 'За время обучения я прослушал больше сорока курсов.'\n",
    "homonym2 = 'Сорока своровала блестящее украшение со стола.'\n",
    "mystem_analyzer = Mystem() # инициализирую объект с дефолтными параметрами\n",
    "\n",
    "print(mystem_analyzer.analyze(homonym1)[-5])\n",
    "print(mystem_analyzer.analyze(homonym2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Словарь, закон Ципфа и закон Хипса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закон Ципфа -- эмпирическая закономерность: если все слова корпуса текста упорядочить по убыванию частоты их использования, то частота n-го слова в таком списке окажется приблизительно обратно пропорциональной его порядковому номеру n. Иными словами, частотность слов убывает очень быстро."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2859142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['first_timee', 'хоть', 'я', 'и', 'школота', 'но', 'поверь', 'у', 'нас', 'то']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [token for tweet in df.text for token in word_tokenize(tweet) if token not in punctuation]\n",
    "print(len(corpus))\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('не', 69267),\n",
       " ('и', 54916),\n",
       " ('в', 52853),\n",
       " ('я', 52506),\n",
       " ('RT', 38070),\n",
       " ('на', 35715),\n",
       " ('http', 32992),\n",
       " ('что', 31472),\n",
       " ('...', 28773),\n",
       " ('с', 27176)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict = Counter(corpus)\n",
    "freq_dict_sorted= sorted(freq_dict.items(), key=lambda x: -x[1])\n",
    "list(freq_dict_sorted)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "first_100_freqs = [freq for word, freq in freq_dict_sorted[:100]]\n",
    "plt.plot(first_100_freqs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закон Хипса -- обратная сторона закона Ципфа. Он описывает, что чем больше корпус, тем меньше новых слов добавляется с добавлением новых текстов. В какой-то момент корпус насыщается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## О важности эксплоративного анализа\n",
    "\n",
    "Но иногда пунктуация бывает и не шумом -- главное отталкиваться от задачи. Что будет если вообще не убирать пунктуацию?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.81      0.75       223\n",
      "    positive       0.92      0.86      0.89       571\n",
      "\n",
      "    accuracy                           0.85       794\n",
      "   macro avg       0.81      0.84      0.82       794\n",
      "weighted avg       0.86      0.85      0.85       794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Шок! Стоило оставить пунктуацию -- и все метрики равны 1. Как это получилось? Среди неё были очень значимые токены (как вы думаете, какие?). Найдите фичи с самыми большими коэффициэнтами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как один из супер-значительных токенов справится с классификацией безо всякого машинного обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       1.00      0.85      0.92     32733\n",
      "   positive       0.83      1.00      0.91     23976\n",
      "\n",
      "avg / total       0.93      0.91      0.91     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cool_token = \n",
    "pred = ['positive' if cool_token in tweet else 'negative' for tweet in x_test]\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Символьные n-граммы\n",
    "\n",
    "Теперь в качестве фичей используем, например, униграммы символов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.44      0.79      0.57       145\n",
      "    positive       0.94      0.78      0.85       649\n",
      "\n",
      "    accuracy                           0.78       794\n",
      "   macro avg       0.69      0.78      0.71       794\n",
      "weighted avg       0.85      0.78      0.80       794\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем-то, теперь уже понятно, почему на этих данных здесь 1. Просто знайте, что так можно: для некторых задач (например, для определения языка) фичи-символьные n-граммы решительно рулят.\n",
    "\n",
    "Ещё одна замечательная особенность фичей-символов: токенизация и лемматизация не нужна, можно использовать такой подход для языков, у которых нет готвых анализаторов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fastText\n",
    "\n",
    "https://fasttext.cc/docs/en/supervised-tutorial.html\n",
    "\n",
    "Если осталось время -- сами поизучайте этот модуль и попробуйти применить его к нашей задаче."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
